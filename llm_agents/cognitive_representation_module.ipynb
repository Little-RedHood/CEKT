{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BElLNM8kFoWZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"' Install Dependencies \"\"\"\n",
    "\n",
    "!pip install -U langchain langchain-openai langchain-deepseek langchain-qwq"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" Setting Environment Variables \"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "except Exception as e:\n",
    "    print(\"Not in Colab or already mounted.\")\n",
    "\n",
    "with open(\"./drive/MyDrive/llm_agents/data/data_config.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_config = json.load(f)\n",
    "\n",
    "# [\"gpt-4.1-2025-04-14\", \"o3-2025-04-16\"]  For details, see https://platform.openai.com/docs/\n",
    "os.environ[\"OPENAI_API_BASE\"] = data_config.get(\"large_language_model\").get(\"openai\").get(\"openai_api_base\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = data_config.get(\"large_language_model\").get(\"openai\").get(\"openai_api_key\")\n",
    "\n",
    "# [\"deepseek-chat\", \"deepseek-reasoner\"]  For details, see https://api-docs.deepseek.com/\n",
    "os.environ[\"DEEPSEEK_API_BASE\"] = data_config.get(\"large_language_model\").get(\"deepseek\").get(\"deepseek_api_base\")\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = data_config.get(\"large_language_model\").get(\"deepseek\").get(\"deepseek_api_key\")\n",
    "\n",
    "# [\"llama3.1-70b-instruct\", \"qwen3-32b\"]  For details, see https://bailian.console.aliyun.com/\n",
    "os.environ[\"DASHSCOPE_API_BASE\"] = data_config.get(\"large_language_model\").get(\"aliyuncs\").get(\"dashscope_api_base\")\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = data_config.get(\"large_language_model\").get(\"aliyuncs\").get(\"dashscope_api_key\")\n"
   ],
   "metadata": {
    "id": "jvsQWh5WPZyv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import ast\n",
    "from typing import Any\n",
    "from pydantic import Field\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_qwq import ChatQwQ\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "except Exception as e:\n",
    "    print(\"Not in Colab or already mounted.\")\n",
    "\n",
    "# ======================================================================\n",
    "#                         Global Configuration\n",
    "# ======================================================================\n",
    "config = {}\n",
    "\n",
    "\n",
    "def set_config(config_file_path, dataset_name):\n",
    "    global config\n",
    "\n",
    "    with open(config_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data_config = json.load(f)\n",
    "\n",
    "    config = {\n",
    "        \"MODEL_NAME\": \"gpt-4.1-2025-04-14\",\n",
    "\n",
    "        \"KNOWLEDGE_BASE_TEMPLATE\": os.path.join(data_config.get(\"prompt\").get(\"dpath\"),\n",
    "                                                data_config.get(\"prompt\").get(\"knowledge_base_template\")),\n",
    "        \"QK_PROMPT\": os.path.join(data_config.get(\"prompt\").get(\"dpath\"), data_config.get(\"prompt\").get(\"qk_prompt\")),\n",
    "        \"KC_RANGE_PROMPT\": os.path.join(data_config.get(\"prompt\").get(\"dpath\"),\n",
    "                                        data_config.get(\"prompt\").get(\"kc_range_prompt\")),\n",
    "        \"KC_USE_PROMPT\": os.path.join(data_config.get(\"prompt\").get(\"dpath\"),\n",
    "                                      data_config.get(\"prompt\").get(\"kc_use_prompt\")),\n",
    "        \"QKC_PROMPT\": os.path.join(data_config.get(\"prompt\").get(\"dpath\"), data_config.get(\"prompt\").get(\"qkc_prompt\")),\n",
    "\n",
    "        \"QUESTION_FILE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"dpath\"),\n",
    "                                           data_config.get(\"dataset\").get(dataset_name).get(\"question_file\")),\n",
    "        \"KNOWLEDGE_TAGS_FILE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"dpath\"),\n",
    "                                                 data_config.get(\"dataset\").get(dataset_name).get(\"knowledge_file\")),\n",
    "\n",
    "        \"QK_SAVE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"save_path\"),\n",
    "                                     data_config.get(\"dataset\").get(dataset_name).get(\"(llm agents) qk_file\")),\n",
    "        \"KC_USE_SAVE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"save_path\"),\n",
    "                                         data_config.get(\"dataset\").get(dataset_name).get(\"(llm agents) kc_use_file\")),\n",
    "        \"QKC_SAVE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"save_path\"),\n",
    "                                      data_config.get(\"dataset\").get(dataset_name).get(\"(llm agents) qkc_file\"))\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#                          LLM Initialization\n",
    "# ======================================================================\n",
    "def set_llm(model_name=\"gpt-4.1-2025-04-14\"):\n",
    "    if model_name in [\"gpt-4.1-2025-04-14\"]:\n",
    "        llm = ChatOpenAI(\n",
    "            model=model_name,\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2\n",
    "        )\n",
    "    elif model_name in [\"deepseek-chat\"]:\n",
    "        llm = ChatDeepSeek(\n",
    "            model=model_name,\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2\n",
    "        )\n",
    "    elif model_name in [\"llama3.1-70b-instruct\", \"qwen3-32b\"]:\n",
    "        llm = ChatQwQ(\n",
    "            model=model_name,\n",
    "            max_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model name: {model_name}\")\n",
    "\n",
    "    return llm\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#      Phase 1: Generating Knowledge Components and Their Weights\n",
    "# ======================================================================\n",
    "class IdentifyQuestionKnowledgeComponents(BaseTool):\n",
    "    name: str = \"IdentifyQuestionKnowledgeComponents\"\n",
    "    description: str = (\n",
    "        \"Use this tool to identify the 1 to 5 most relevant knowledge components associated with a given question. \"\n",
    "        \"Assign a numeric weight (float, two decimal places) to each selected knowledge component, reflecting its relative importance. \"\n",
    "        \"Ensure that the sum of all weights strictly equals 1.00. \"\n",
    "        \"Provide the 'question_description' parameter, which represents the description of the question.\"\n",
    "    )\n",
    "    llm: Any = Field(default=None)\n",
    "\n",
    "    def _run(self, question_description: str):\n",
    "        with open(config.get(\"QK_PROMPT\"), \"r\", encoding=\"utf-8\") as file:\n",
    "            qk_prompt = file.read()\n",
    "\n",
    "        df_k = pd.read_csv(config.get(\"KNOWLEDGE_TAGS_FILE_PATH\"))\n",
    "        knowledge_tags = list(df_k['knowledge_component_name'])\n",
    "        qk_prompt = qk_prompt.replace(\"{placeholder - domain knowledge components}\",\n",
    "                                      \"{\" + ', '.join(knowledge_tags) + \"}\")\n",
    "        prompt = qk_prompt + \"\\n\" + question_description\n",
    "\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = self.llm.invoke(messages)\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "class Phase1Executor:\n",
    "    def __init__(self, llm, role, task, background_knowledge, tools, final_answer_format, config, history_window=5):\n",
    "        self.llm = llm\n",
    "        self.role = role\n",
    "        self.task = task\n",
    "        self.background_knowledge = background_knowledge\n",
    "        self.tools = tools\n",
    "        self.tool_names = \", \".join([tool.name for tool in tools])\n",
    "        self.final_answer_format = final_answer_format\n",
    "        self.config = config\n",
    "\n",
    "        with open(self.config.get(\"KNOWLEDGE_BASE_TEMPLATE\"), \"r\", encoding=\"utf-8\") as file:\n",
    "            knowledge_base_template = file.read()\n",
    "\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"role\", \"task\", \"background_knowledge\", \"tools\", \"tool_names\", \"final_answer_format\",\n",
    "                             \"input\", \"agent_scratchpad\"],\n",
    "            template=knowledge_base_template,\n",
    "            validate_template=False\n",
    "        )\n",
    "\n",
    "        self.agent_1 = create_react_agent(llm=self.llm, tools=self.tools, prompt=self.prompt)\n",
    "        self.agent_executor_1 = AgentExecutor(agent=self.agent_1, tools=self.tools, verbose=True,\n",
    "                                              handle_parsing_errors=True)\n",
    "\n",
    "        self.history = []\n",
    "        self.history_window = history_window\n",
    "\n",
    "    # Return formatted string of previous m rounds (Q&A) for current prompt.\n",
    "    def get_history(self):\n",
    "        if not self.history:\n",
    "            return \"\"\n",
    "\n",
    "        history_lines = []\n",
    "        for idx, rec in enumerate(self.history):\n",
    "            history_lines.append(\n",
    "                f\"[History round {idx + 1}]\\nQuestion (ID: {rec['q_id']}): {rec['input']}\\nOutput: {rec['output']}\\n\"\n",
    "            )\n",
    "        return \"\\n\".join(history_lines)\n",
    "\n",
    "    # Get each question information.\n",
    "    def load_data(self, q_file_path):\n",
    "        data = pd.read_csv(q_file_path)\n",
    "        q_ids = data[\"question_id\"].tolist()\n",
    "        q_texts = data[\"description\"].tolist()\n",
    "\n",
    "        return q_ids, q_texts\n",
    "\n",
    "    # Save result ((llm agents_{model_name}) question_knowledge.csv).\n",
    "    def save_data(self, q_id, response, save_file_path):\n",
    "        df = pd.DataFrame([(q_id, response)], columns=[\"question_id\", \"knowledge_component\"])\n",
    "        header = not os.path.exists(save_file_path)\n",
    "        df.to_csv(save_file_path, mode=\"a\", header=header, index=False)\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            q_ids, q_texts = self.load_data(self.config.get(\"QUESTION_FILE_PATH\"))\n",
    "            for i in tqdm(range(len(q_ids)), desc=\"Processing questions\"):\n",
    "                # for i in tqdm(range(1), desc=\"Processing questions\"):\n",
    "                history_lines = self.get_history()\n",
    "                agent_input = \"[question_description]: \" + str(q_texts[i])\n",
    "                if history_lines:\n",
    "                    agent_input = history_lines + \"\\n\" + agent_input\n",
    "\n",
    "                print(agent_input)\n",
    "                response = self.agent_executor_1.invoke({\n",
    "                    \"role\": self.role,\n",
    "                    \"task\": self.task,\n",
    "                    \"background_knowledge\": self.background_knowledge,\n",
    "                    \"tools\": self.tool_names,\n",
    "                    \"tool_names\": self.tool_names,\n",
    "                    \"final_answer_format\": self.final_answer_format,\n",
    "                    # \"input\": \"[question_description]: \" + str(q_texts[i]),\n",
    "                    \"input\": agent_input,\n",
    "                    \"agent_scratchpad\": \"\"\n",
    "                })\n",
    "\n",
    "                output = response.get(\"output\")\n",
    "                print(f\"{q_ids[i]}: {output}\")\n",
    "                self.save_data(str(q_ids[i]), output,\n",
    "                               self.config.get(\"QK_SAVE_PATH\").format(model_name=self.config.get(\"MODEL_NAME\")))\n",
    "\n",
    "                if len(self.history) >= self.history_window:\n",
    "                    self.history.pop(0)\n",
    "                self.history.append({\n",
    "                    \"q_id\": q_ids[i],\n",
    "                    \"input\": q_texts[i],\n",
    "                    \"output\": output\n",
    "                })\n",
    "\n",
    "                time.sleep(5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Phase1Executor Error]: {repr(e)}\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#      Phase 2: Enriching the Attributes of Knowledge Components\n",
    "# ======================================================================\n",
    "class DetermineCognitiveLevelRange(BaseTool):\n",
    "    name: str = \"DetermineCognitiveLevelRange\"\n",
    "    description: str = (\n",
    "        \"Use this tool to determine the continuous range of cognitive levels associated with a given knowledge component. \"\n",
    "        \"List all cognitive levels that are relevant for the specified knowledge component, ensuring the selection forms a continuous range. \"\n",
    "        \"Provide the 'knowledge_component' parameter, which represents the exact name of the knowledge component (e.g., 'array').\"\n",
    "    )\n",
    "    llm: Any = Field(default=None)\n",
    "\n",
    "    def _run(self, knowledge_component: str):\n",
    "        with open(config.get(\"KC_RANGE_PROMPT\"), \"r\", encoding=\"utf-8\") as file:\n",
    "            kc_range_prompt = file.read()\n",
    "\n",
    "        prompt = kc_range_prompt + \"\\n\" + knowledge_component\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = self.llm.invoke(messages)\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "class DescribeCognitiveLevelUsage(BaseTool):\n",
    "    name: str = \"DescribeCognitiveLevelUsage\"\n",
    "    description: str = (\n",
    "        \"Use this tool to generate the common uses for each cognitive level associated with a given knowledge component. \"\n",
    "        \"Provide the 'cognitive_level_range' parameter, which is a string in the format 'knowledge_component: {cognitive_level_1, cognitive_level_2, ...}', \"\n",
    "        \"such as 'array: {Remembering, Understanding, Applying}'. \"\n",
    "        \"The tool should output the typical usage of each cognitive level within the context of the specified knowledge component.\"\n",
    "    )\n",
    "    llm: Any = Field(default=None)\n",
    "\n",
    "    def _run(self, cognitive_level_range: str):\n",
    "        with open(config.get(\"KC_USE_PROMPT\"), \"r\", encoding=\"utf-8\") as file:\n",
    "            kc_use_prompt = file.read()\n",
    "\n",
    "        prompt = kc_use_prompt + \"\\n\" + cognitive_level_range\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = self.llm.invoke(messages)\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "class Phase2Executor:\n",
    "    def __init__(self, llm, role, task, background_knowledge, tools, final_answer_format, config, history_window=5):\n",
    "        self.llm = llm\n",
    "        self.role = role\n",
    "        self.task = task\n",
    "        self.background_knowledge = background_knowledge\n",
    "        self.tools = tools\n",
    "        self.tool_names = \", \".join([tool.name for tool in tools])\n",
    "        self.final_answer_format = final_answer_format\n",
    "        self.config = config\n",
    "\n",
    "        with open(self.config.get(\"KNOWLEDGE_BASE_TEMPLATE\"), \"r\", encoding=\"utf-8\") as file:\n",
    "            knowledge_base_template = file.read()\n",
    "\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"role\", \"task\", \"background_knowledge\", \"tools\", \"tool_names\", \"final_answer_format\",\n",
    "                             \"input\", \"agent_scratchpad\"],\n",
    "            template=knowledge_base_template,\n",
    "            validate_template=False\n",
    "        )\n",
    "\n",
    "        self.agent_2 = create_react_agent(llm=self.llm, tools=self.tools, prompt=self.prompt)\n",
    "        self.agent_executor_2 = AgentExecutor(agent=self.agent_2, tools=self.tools, verbose=True,\n",
    "                                              handle_parsing_errors=True)\n",
    "\n",
    "        self.history = []\n",
    "        self.history_window = history_window\n",
    "\n",
    "    # Return formatted string of previous m rounds (Q&A) for current prompt.\n",
    "    def get_history(self):\n",
    "        if not self.history:\n",
    "            return \"\"\n",
    "\n",
    "        history_lines = []\n",
    "        for idx, rec in enumerate(self.history):\n",
    "            history_lines.append(\n",
    "                f\"[History round {idx + 1}]\\nKnowledge Component (ID: {rec['k_id']}): {rec['input']}\\nOutput: {rec['output']}\\n\"\n",
    "            )\n",
    "        return \"\\n\".join(history_lines)\n",
    "\n",
    "    # Get each knowledge component information.\n",
    "    def load_data(self, k_file_path):\n",
    "        data = pd.read_csv(k_file_path)\n",
    "        k_ids = data[\"knowledge_component_id\"].tolist()\n",
    "        k_names = data[\"knowledge_component_name\"].tolist()\n",
    "\n",
    "        return k_ids, k_names\n",
    "\n",
    "    # Save result ((llm agents_{model_name}) knowledge_cognitive_use.csv).\n",
    "    def save_data(self, k_id, k_name, response, save_file_path):\n",
    "        df = pd.DataFrame([(k_id, k_name, response)],\n",
    "                          columns=[\"knowledge_component_id\", \"knowledge_component_name\", \"cognitive_level_use\"])\n",
    "        header = not os.path.exists(save_file_path)\n",
    "        df.to_csv(save_file_path, mode=\"a\", header=header, index=False)\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            k_ids, k_names = self.load_data(self.config.get(\"KNOWLEDGE_TAGS_FILE_PATH\"))\n",
    "            for i in tqdm(range(len(k_ids)), desc=\"Processing questions\"):\n",
    "                # for i in tqdm(range(1), desc=\"Processing questions\"):\n",
    "                history_lines = self.get_history()\n",
    "                agent_input = \"[knowledge_component]: \" + str(k_names[i])\n",
    "                if history_lines:\n",
    "                    agent_input = history_lines + \"\\n\" + agent_input\n",
    "\n",
    "                print(agent_input)\n",
    "\n",
    "                response = self.agent_executor_2.invoke({\n",
    "                    \"role\": self.role,\n",
    "                    \"task\": self.task,\n",
    "                    \"background_knowledge\": self.background_knowledge,\n",
    "                    \"tools\": self.tool_names,\n",
    "                    \"tool_names\": self.tool_names,\n",
    "                    \"final_answer_format\": self.final_answer_format,\n",
    "                    \"input\": agent_input,\n",
    "                    \"agent_scratchpad\": \"\"\n",
    "                })\n",
    "\n",
    "                output = response.get(\"output\")\n",
    "                print(f\"{k_ids[i]}: {output}\")\n",
    "                self.save_data(str(k_ids[i]), str(k_names[i]), output,\n",
    "                               self.config.get(\"KC_USE_SAVE_PATH\").format(model_name=self.config.get(\"MODEL_NAME\")))\n",
    "\n",
    "                if len(self.history) >= self.history_window:\n",
    "                    self.history.pop(0)\n",
    "                self.history.append({\n",
    "                    \"k_id\": k_ids[i],\n",
    "                    \"input\": k_names[i],\n",
    "                    \"output\": output\n",
    "                })\n",
    "\n",
    "                time.sleep(5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Phase3Executor Error]: {repr(e)}\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#   Phase 3: Determining the Cognitive Level of Knowledge Components\n",
    "# ======================================================================\n",
    "class DetermineQuestionKCCognitiveLevel(BaseTool):\n",
    "    name: str = \"DetermineQuestionKCCognitiveLevel\"\n",
    "    description: str = (\n",
    "        \"Use this tool to identify which cognitive level is involved for each knowledge component in a given question. \"\n",
    "        \"Provide the 'total_question_information' parameter, which must be a JSON object with the following format: \"\n",
    "        '''\n",
    "        {\n",
    "          \"question\": \"The target question text.\",\n",
    "          \"knowledge_components\": [\n",
    "            {\n",
    "              \"name\": \"knowledge component 1\",\n",
    "              \"weight\": 0.45,\n",
    "              \"cognitive_levels\": [\"Remembering\", \"Understanding\", \"Applying\"],\n",
    "              \"common_uses\": {\n",
    "                \"Remembering\": \"Typical usage at remembering level.\",\n",
    "                \"Understanding\": \"Typical usage at understanding level.\",\n",
    "                \"Applying\": \"Typical usage at applying level.\"\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"knowledge component 2\",\n",
    "              \"weight\": 0.55,\n",
    "              \"cognitive_levels\": [\"Remembering\", \"Understanding\"],\n",
    "              \"common_uses\": {\n",
    "                \"Remembering\": \"Typical usage at remembering level.\",\n",
    "                \"Understanding\": \"Typical usage at understanding level.\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "        '''\n",
    "        \"The tool should output a JSON object mapping each knowledge component name to the selected cognitive level for this question.\"\n",
    "    )\n",
    "    llm: Any = Field(default=None)\n",
    "\n",
    "    def _run(self, total_question_information: str):\n",
    "        with open(config.get(\"QKC_PROMPT\"), \"r\", encoding=\"utf-8\") as file:\n",
    "            qkc_prompt = file.read()\n",
    "\n",
    "        prompt = qkc_prompt + \"\\n\" + total_question_information\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = self.llm.invoke(messages)\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "class Phase3Executor:\n",
    "    def __init__(self, llm, role, task, background_knowledge, tools, final_answer_format, config, history_window=5):\n",
    "        self.llm = llm\n",
    "        self.role = role\n",
    "        self.task = task\n",
    "        self.background_knowledge = background_knowledge\n",
    "        self.tools = tools\n",
    "        self.tool_names = \", \".join([tool.name for tool in tools])\n",
    "        self.final_answer_format = final_answer_format\n",
    "        self.config = config\n",
    "\n",
    "        with open(self.config.get(\"KNOWLEDGE_BASE_TEMPLATE\"), \"r\", encoding=\"utf-8\") as file:\n",
    "            knowledge_base_template = file.read()\n",
    "\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"role\", \"task\", \"background_knowledge\", \"tools\", \"tool_names\", \"final_answer_format\",\n",
    "                             \"input\", \"agent_scratchpad\"],\n",
    "            template=knowledge_base_template,\n",
    "            validate_template=False\n",
    "        )\n",
    "\n",
    "        self.agent_3 = create_react_agent(llm=self.llm, tools=self.tools, prompt=self.prompt)\n",
    "        self.agent_executor_3 = AgentExecutor(agent=self.agent_3, tools=self.tools, verbose=True,\n",
    "                                              handle_parsing_errors=True)\n",
    "\n",
    "        self.history = []\n",
    "        self.history_window = history_window\n",
    "\n",
    "    # Return formatted string of previous m rounds (Q&A) for current prompt.\n",
    "    def get_history(self):\n",
    "        if not self.history:\n",
    "            return \"\"\n",
    "\n",
    "        history_lines = []\n",
    "        for idx, rec in enumerate(self.history):\n",
    "            history_lines.append(\n",
    "                f\"[History round {idx + 1}]\\nQuestion (ID: {rec['q_id']}): {rec['input']}\\nOutput: {rec['output']}\\n\"\n",
    "            )\n",
    "        return \"\\n\".join(history_lines)\n",
    "\n",
    "    # Get each question and its total informations.\n",
    "    def load_data(self, q_file_path, qk_file_path, kc_use_file_path):\n",
    "        df_q = pd.read_csv(q_file_path)\n",
    "        df_qk = pd.read_csv(qk_file_path)\n",
    "        df_kc_use = pd.read_csv(kc_use_file_path)\n",
    "\n",
    "        q_ids = df_q[\"question_id\"].tolist()\n",
    "        q_texts = df_q[\"description\"].tolist()\n",
    "        qid_text_dict = dict(zip(q_ids, q_texts))\n",
    "\n",
    "        # Input -- 35: {\"array\": \"0.5\", \"binary search\": \"0.4\", \"hello\": \"0.l\"}\n",
    "        #   → knowledge_name_set: {\"array\", \"binary search\", \"hello\"}\n",
    "        #   → knowledge_name_set: {\"array\", \"binary search\"}\n",
    "        #   → knowledge_label： {\"array\": \"0.5\", \"binary search\": \"0.4\"}\n",
    "        # Output -- qk_dict: {35: {\"array\": \"0.5\", \"binary search\": \"0.4\"}, ...}\n",
    "        qk_dict = {}\n",
    "        kc_name_set = set(df_kc_use[\"knowledge_component_name\"].tolist())\n",
    "        for index, row in df_qk.iterrows():\n",
    "            knowledge_label = json.loads(row[\"knowledge_component\"])\n",
    "\n",
    "            # Delete knowledge components that do not exist in kc_use_dict\n",
    "            filtered = {k: v for k, v in knowledge_label.items() if k in kc_name_set}\n",
    "            qk_dict[row[\"question_id\"]] = filtered\n",
    "\n",
    "        # kc_range_dict: {\"knowledge_component_name\": \"cognitive_level_range\"}\n",
    "        kc_range_dict = {}\n",
    "        for _, row in df_kc_use.iterrows():\n",
    "            kc_name = row[\"knowledge_component_name\"]\n",
    "            level_use = ast.literal_eval(row[\"cognitive_level_use\"])\n",
    "            kc_range_dict[kc_name] = list(level_use.keys())\n",
    "\n",
    "        # kc_use_dict: {\"knowledge_component_name\": \"cognitive_level_use.\"}\n",
    "        kc_use_dict = {}\n",
    "        for index, row in df_kc_use.iterrows():\n",
    "            kc_use_dict[row[\"knowledge_component_name\"]] = row[\"cognitive_level_use\"]\n",
    "\n",
    "        # See the format in qkc_prompt.txt for details.\n",
    "        total_q_information = []\n",
    "        for q_id, knowledge_label in qk_dict.items():\n",
    "            q_information = {\"question\": qid_text_dict.get(q_id), \"knowledge_components\": []}\n",
    "\n",
    "            for k_name in set(knowledge_label.keys()):\n",
    "                q_information[\"knowledge_components\"].append({\n",
    "                    \"name\": k_name,\n",
    "                    \"weight\": knowledge_label.get(k_name),\n",
    "                    \"cognitive_levels\": kc_range_dict.get(k_name),\n",
    "                    \"common_uses\": kc_use_dict.get(k_name)\n",
    "                })\n",
    "\n",
    "            total_q_information.append(q_information)\n",
    "\n",
    "        return q_ids, total_q_information\n",
    "\n",
    "    # Save result ((llm agents_{model_name}) question_knowledge_cognitive.csv).\n",
    "    def save_data(self, q_id, response, save_file_path):\n",
    "        df = pd.DataFrame([(q_id, response)], columns=[\"question_id\", \"knowledge_component_cognitive\"])\n",
    "        header = not os.path.exists(save_file_path)\n",
    "        df.to_csv(save_file_path, mode=\"a\", header=header, index=False)\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            q_ids, total_q_information = self.load_data(\n",
    "                q_file_path=self.config.get(\"QUESTION_FILE_PATH\"),\n",
    "                qk_file_path=self.config.get(\"QK_SAVE_PATH\").format(model_name=self.config.get(\"MODEL_NAME\")),\n",
    "                kc_use_file_path=self.config.get(\"KC_USE_SAVE_PATH\").format(model_name=self.config.get(\"MODEL_NAME\"))\n",
    "            )\n",
    "\n",
    "            for i in tqdm(range(len(total_q_information)), desc=\"Processing questions\"):\n",
    "                # for i in tqdm(range(1), desc=\"Processing questions\"):\n",
    "                history_lines = self.get_history()\n",
    "                agent_input = \"[total_question_information]: \" + str(total_q_information[i])\n",
    "                if history_lines:\n",
    "                    agent_input = history_lines + \"\\n\" + agent_input\n",
    "\n",
    "                print(agent_input)\n",
    "\n",
    "                response = self.agent_executor_3.invoke({\n",
    "                    \"role\": self.role,\n",
    "                    \"task\": self.task,\n",
    "                    \"background_knowledge\": self.background_knowledge,\n",
    "                    \"tools\": self.tool_names,\n",
    "                    \"tool_names\": self.tool_names,\n",
    "                    \"final_answer_format\": self.final_answer_format,\n",
    "                    \"input\": agent_input,\n",
    "                    \"agent_scratchpad\": \"\"\n",
    "                })\n",
    "\n",
    "                output = response.get(\"output\")\n",
    "                print(f\"{q_ids[i]}: {output}\")\n",
    "                self.save_data(str(q_ids[i]), output,\n",
    "                               self.config.get(\"QKC_SAVE_PATH\").format(model_name=self.config.get(\"MODEL_NAME\")))\n",
    "\n",
    "                if len(self.history) >= self.history_window:\n",
    "                    self.history.pop(0)\n",
    "                self.history.append({\n",
    "                    \"q_id\": q_ids[i],\n",
    "                    \"input\": total_q_information[i],\n",
    "                    \"output\": output\n",
    "                })\n",
    "\n",
    "                time.sleep(5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Phase3Executor Error]: {repr(e)}\")\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "#                                     Main\n",
    "# ======================================================================================\n",
    "def main(config_file_path, dataset_name):\n",
    "    set_config(config_file_path, dataset_name)\n",
    "    llm = set_llm(config.get(\"MODEL_NAME\"))\n",
    "\n",
    "    phase_1_executor = Phase1Executor(\n",
    "        llm=llm,\n",
    "        role=\"Educational knowledge analysis expert.\",\n",
    "        task=(\n",
    "            \"You are given a [question_description]. \"\n",
    "            \"Your task is to identify the most relevant knowledge components (1 to 5), and assign each a numeric weight reflecting its relative importance. \"\n",
    "            \"When calling the tool IdentifyQuestionKnowledgeComponents, always use the original question text as the 'question_description' parameter, without any summarization or modification.\"\n",
    "        ),\n",
    "        background_knowledge=(\n",
    "            \"**Knowledge Component for Computer Science**:\\n\"\n",
    "            \"[string, two pointers, bit manipulation, prefix sum, hash function, rolling hash, database, array, tree array, linked list, doubly-linked list, hash table, tree, binary tree, trie, segment tree, binary search tree, heap, stack, monotonic stack, queue, monotonic queue, graph, union find, ordered set, recursion, enumeration, divide and conquer, binary search, topological sort, merge sort, counting sort, bucket sort, dynamic programming, memorization search, greedy, backtracking, depth-first search, breadth-first search, sliding window, state compression, string matching, shortest path, minimum spanning tree, design, simulation, search, sort, union set, mathematics, loop statement, number theory, pascal's triangle, matrix, combinatorics, branch, game, 01 backpack, binary exponentiation, iteration, big integer, prime number, fibonacci sequence, pointer, macro, struct, if statement, brute force, dynamic allocation, array of structures, radix sort, quick sort, hash map, heap sort, top-k, kruskal, circular queue, circular linked list, binary graph, operator, library function]\\n\"\n",
    "            \"**Knowledge Component for Mathematics**:\\n\"\n",
    "            \"[Decimals, Factors, Multiples and Primes, Fractions, Percentages, Proportion, Ratio, Expanding Brackets, Factorising, Straight Line Graphs, Quadratic Graphs, Graphs of Trigonometric Functions, Inequalities, Sequences, Simultaneous Equations, Linear Equations, Quadratic Equations, Substitution into Formula, Transformation of Functions, Angles, Area of Simple Shapes, Bearings, Circle Theorems, Co-ordinates, Properties of Polygons, Perimeter, Properties of Quadrilaterals, Symmetry, Reflection, Rotation, Enlargement, Translation and Vectors, Basic Trigonometry, Units of Measurement, Volume and Surface Area, Box Plots, Histogram, Pie Chart, Probability of Single Events, Data Collection, Sampling and Bias, Scatter Diagram, Time Series and Line Graphs, Matrices, Solving Equations, Formula, Equation of a Circle, Linear Sequences (nth term), Quadratic Sequences, Measuring Angles, Basic Angle Facts (straight line, opposite, around a point, etc), Angle Facts with Parallel Lines, Angles in Polygons, Parts of a Circle, Circumference, Area of a Circle, Sectors of a Circle, Volume of Prisms, Construct Triangle, Length Units, Area Units, Volume and Capacity Units, Weight Units, Rounding to Decimal Places, Rounding to Significant Figures, Estimation, Prime Numbers and Prime Factors, Equivalent Fractions, Simplifying Fractions, Converting Mixed Number and Improper Fractions, Adding and Subtracting Fractions, Multiplying Fractions, Dividing Fractions, Percentage Increase and Decrease, Squares, Cubes, etc, Square Roots, Cube Roots, etc, Laws of Indices, Simplifying Surds, Rationalising the Denominator, Simplifying Expressions by Collecting Like Terms, Multiplying Terms, Dividing Terms, Difference of Two Squares, Algebraic Fractions, Completing the Square, Plotting Lines from Tables of Values, Finding the Equation of a Line, Parallel Lines, Perpendicular Lines, Sketching from Factorised Form, Graphical Solution of Quadratic Equations, Speed, Distance, Time, Density, Pythagoras, Similarity and Congruency, Line Symmetry, Right-angled Triangles (SOHCAHTOA), Non Right-angled Triangles (Sine and Cosine Rules), Area of Non Right-angled Triangles, Permutations and Combinations, Tally Charts, Frequency Diagram and Frequency Polygon, Venn Diagrams, Probability, Tree Diagrams with Independent Events, Arithmetic Sequences, Sigma Notation, Summing Series, Basic dy/dx, Differentiation from First Principals, Finding Maximums and Minimums, Integration, Radians, Solving Basic Trigonometric Equations, Basic Trigonometric Identities, Laws of Logarithms, Solving Equations with Exps and Logs, Domain and Range, Inverse Functions, Composite Functions, Standard Deviation and Variance from Discrete Data, Factorial Notation]\\n\"\n",
    "        ),\n",
    "        tools=[IdentifyQuestionKnowledgeComponents(llm=llm)],\n",
    "        final_answer_format=\"\"\"{\"knowledge component 1\": weight 1, \"knowledge component 2\": weight 2}\"\"\",\n",
    "        config=config,\n",
    "        history_window=5\n",
    "    )\n",
    "\n",
    "    phase_2_executor = Phase2Executor(\n",
    "        llm=llm,\n",
    "        role=\"Educational cognitive analysis expert.\",\n",
    "        task=(\n",
    "            \"You are given a [knowledge component]. \"\n",
    "            \"Your task is to: \"\n",
    "            \"1) Determine the continuous range of cognitive levels (abilities) involved in this knowledge component. \"\n",
    "            \"2) For each identified cognitive level, describe its common uses in the context of the given knowledge component. \"\n",
    "            \"When calling the tool DetermineCognitiveLevelRange, always use the original knowledge component name as the 'knowledge_component' parameter, without any summarization or modification. \"\n",
    "            \"When calling the tool DescribeCognitiveLevelUsage, always provide the knowledge component and its cognitive levels in the format 'knowledge_component: {cognitive_level_1, cognitive_level_2, ...}' as the 'cognitive_level_range' parameter, exactly as obtained from the previous step, without any alteration.\"\n",
    "        ),\n",
    "        background_knowledge=(\n",
    "            \"**Cognitive Level Definitions**:\\n\"\n",
    "            \"**Remembering**: The first level of cognitive levels, focusing on recalling basic definitions and attributes of the knowledge component. It often involves direct recollection or simple enumeration in applications.\\n\"\n",
    "            \"**Understanding**: The second level of cognitive levels, involving common operations and basic applications, such as demonstrating basic operations and explaining how they work.\\n\"\n",
    "            \"**Applying**: The third level of cognitive levels, involving the use of knowledge to solve practical problems or construct solutions in new scenarios. This level emphasizes the application of knowledge to specific real-world situations.\\n\"\n",
    "            \"**Analyzing**: The fourth level of cognitive levels, with higher requirements for the use of the knowledge component, focusing on deep analysis to optimize solutions or improve methods.\\n\"\n",
    "            \"**Evaluating**: The fifth level of cognitive levels requires using the knowledge component to be assessed based on specific criteria (effectiveness, reliability, efficiency, etc.). This level emphasizes assessing the performance of the knowledge component in theoretical and practical applications, and making decisions on whether to continue using, improve, or replace it.\\n\"\n",
    "            \"**Creating**: The highest level of cognitive levels. It requires integrating the knowledge component with knowledge from other fields to propose creative solutions for meeting needs or solving complex practical problems. This level focuses on creativity and innovation.\\n\"\n",
    "        ),\n",
    "        tools=[DetermineCognitiveLevelRange(llm=llm), DescribeCognitiveLevelUsage(llm=llm)],\n",
    "        final_answer_format=\"\"\"{\"cognitive level 1\": \"usage 1\",  \"cognitive level 2\": \"usage 2\"}\"\"\",\n",
    "        config=config,\n",
    "        history_window=5\n",
    "    )\n",
    "\n",
    "    phase_3_executor = Phase3Executor(\n",
    "        llm=llm,\n",
    "        role=\"Educational cognitive analysis expert.\",\n",
    "        task=(\n",
    "            \"You are given a question and its detailed information. \"\n",
    "            \"Your task is to identify which cognitive level is involved for each knowledge component in the given question. \"\n",
    "            \"When calling the tool DetermineQuestionKCCognitiveLevel, always provide the 'total_question_information' parameter, without any summarization or modification.\"\n",
    "        ),\n",
    "        background_knowledge=(\n",
    "            \"**Cognitive Level Definitions**:\\n\"\n",
    "            \"**Remembering**: The first level of cognitive levels, focusing on recalling basic definitions and attributes of the knowledge component. It often involves direct recollection or simple enumeration in applications.\\n\"\n",
    "            \"**Understanding**: The second level of cognitive levels, involving common operations and basic applications, such as demonstrating basic operations and explaining how they work.\\n\"\n",
    "            \"**Applying**: The third level of cognitive levels, involving the use of knowledge to solve practical problems or construct solutions in new scenarios. This level emphasizes the application of knowledge to specific real-world situations.\\n\"\n",
    "            \"**Analyzing**: The fourth level of cognitive levels, with higher requirements for the use of the knowledge component, focusing on deep analysis to optimize solutions or improve methods.\\n\"\n",
    "            \"**Evaluating**: The fifth level of cognitive levels requires using the knowledge component to be assessed based on specific criteria (effectiveness, reliability, efficiency, etc.). This level emphasizes assessing the performance of the knowledge component in theoretical and practical applications, and making decisions on whether to continue using, improve, or replace it.\\n\"\n",
    "            \"**Creating**: The highest level of cognitive levels. It requires integrating the knowledge component with knowledge from other fields to propose creative solutions for meeting needs or solving complex practical problems. This level focuses on creativity and innovation.\\n\"\n",
    "        ),\n",
    "        tools=[DetermineQuestionKCCognitiveLevel(llm=llm)],\n",
    "        final_answer_format=\"\"\"{\"knowledge component 1\": cognitive level 1, \"knowledge component 2\": cognitive level 2}\"\"\",\n",
    "        config=config,\n",
    "        history_window=5\n",
    "    )\n",
    "\n",
    "    phase_1_executor.run()\n",
    "    phase_2_executor.run()\n",
    "    phase_3_executor.run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(config_file_path=\"./drive/MyDrive/llm_agents/data/data_config.json\", dataset_name=\"bepkt\")\n"
   ],
   "metadata": {
    "id": "gtbkHYkzzDfg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1b990C2_69gSQ6cwYGHhTUxRM8Aw2Vuda",
   "authorship_tag": "ABX9TyMasBZqMXpbIzmGBxLkD0Xm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}