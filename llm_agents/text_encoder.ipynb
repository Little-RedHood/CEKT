{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPMiRtqaG+8hAdTkk+uaUTL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"polT0eFe4k1U"},"outputs":[],"source":["\"\"\"' Install Dependencies \"\"\"\n","\n","!pip install openai\n","!pip install pandas"]},{"cell_type":"code","source":["\"\"\" Interaction Encoder (Part) \"\"\"\n","\n","import os\n","import json\n","\n","import httpx\n","import pandas as pd\n","from openai import OpenAI\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","\n","def get_config(config_file_path, dataset_name):\n","  global config\n","\n","  with open(config_file_path, \"r\", encoding=\"utf-8\") as f:\n","    data_config = json.load(f)\n","\n","  config = {\n","    \"MODEL_NAME\": \"text-embedding-3-small\",\n","    \"OPENAI_API_BASE\": data_config.get(\"large_language_model\").get(\"openai\").get(\"openai_api_base\"),\n","    \"OPENAI_API_KEY\": data_config.get(\"large_language_model\").get(\"openai\").get(\"openai_api_key\"),\n","    \"QUESTION_FILE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"dpath\"), data_config.get(\"dataset\").get(dataset_name).get(\"question_file\")),\n","    \"KNOWLEDGE_FILE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"dpath\"), data_config.get(\"dataset\").get(dataset_name).get(\"knowledge_file\")),\n","    \"COGNITIVE_FILE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"dpath\"), data_config.get(\"dataset\").get(dataset_name).get(\"cognitive_file\")),\n","    \"ENCODING_QUESTION_FILE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"save_path\"), data_config.get(\"dataset\").get(dataset_name).get(\"(encoding) question_file\")),\n","    \"ENCODING_KNOWLEDGE_FILE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"save_path\"), data_config.get(\"dataset\").get(dataset_name).get(\"(encoding) knowledge_file\")),\n","    \"ENCODING_COGNITIVE_FILE_PATH\": os.path.join(data_config.get(\"dataset\").get(dataset_name).get(\"save_path\"), data_config.get(\"dataset\").get(dataset_name).get(\"(encoding) cognitive_file\"))\n","  }\n","\n","\n","def get_llm_encoding(api_base, api_key, text, model=\"text-embedding-3-small\"):\n","  client = OpenAI(\n","    base_url=api_base,\n","    api_key=api_key,\n","    http_client=httpx.Client(base_url=api_base, follow_redirects=True)\n","  )\n","\n","  text = text.replace(\"\\n\", \" \")\n","  return client.embeddings.create(input = [text], model=model).data[0].embedding\n","\n","\n","if __name__ == \"__main__\":\n","  get_config(config_file_path=\"./llm_agents/data/data_config.json\", dataset_name=\"bepkt\")\n","\n","  df_q = pd.read_csv(config.get(\"QUESTION_FILE_PATH\"))\n","  df_q[\"description_encoding\"] = df_q[\"description\"].apply(lambda x: get_llm_encoding(config.get(\"OPENAI_API_BASE\"), config.get(\"OPENAI_API_KEY\"), x))\n","  df_q.to_csv(config.get(\"ENCODING_QUESTION_FILE_PATH\"), index=False)\n","\n","  df_k = pd.read_csv(config.get(\"KNOWLEDGE_FILE_PATH\"))\n","  df_k[\"knowledge_component_encoding\"] = df_k[\"knowledge_component_name\"].apply(lambda x: get_llm_encoding(config.get(\"OPENAI_API_BASE\"), config.get(\"OPENAI_API_KEY\"), x))\n","  df_k.to_csv(config.get(\"ENCODING_KNOWLEDGE_FILE_PATH\"), index=False)\n","\n","  df_c = pd.read_csv(config.get(\"COGNITIVE_FILE_PATH\"))\n","  df_c[\"cognitive_level_encoding\"] = df_c[\"cognitive_level_name\"].apply(lambda x: get_llm_encoding(config.get(\"OPENAI_API_BASE\"), config.get(\"OPENAI_API_KEY\"), x))\n","  df_c.to_csv(config.get(\"ENCODING_COGNITIVE_FILE_PATH\"), index=False)"],"metadata":{"id":"iHu7Wlyy6EMZ"},"execution_count":null,"outputs":[]}]}
